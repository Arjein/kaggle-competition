{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitDataset(Dataset):\n",
    "    def __init__(self, dataFrame: pd.DataFrame, targetColumn: str, transform= False):\n",
    "        self.targetColumn = targetColumn\n",
    "        self.transorm = transform\n",
    "        \n",
    "        if targetColumn != None:\n",
    "            self.X = dataFrame.drop(columns=[targetColumn]).to_numpy(dtype=np.float32) / 255\n",
    "            self.Y = dataFrame[targetColumn].to_numpy(dtype=np.int64)\n",
    "        else:\n",
    "            self.X = dataFrame.to_numpy(dtype=np.float32) / 255\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.targetColumn != None:\n",
    "            if self.transorm:\n",
    "                return self.X[idx].reshape(1,28,28), self.Y[idx]\n",
    "            else:\n",
    "                return self.X[idx], self.Y[idx]\n",
    "        else:\n",
    "            if self.transorm:\n",
    "                return self.X[idx].reshape(1,28,28)\n",
    "            else:\n",
    "                return self.X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df_train, df_val = train_test_split(df, test_size=0.2, random_state=1337)\n",
    "\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "device = 'mps'\n",
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def array_to_image(array):\n",
    "    array = array.numpy()\n",
    "    array = array.flatten()  # Ensure it's 1D\n",
    "    array = array[:784]  # Keep only 784 elements if there is an extra column\n",
    "    array = np.reshape(array, (28, 28))  # Reshape to 28x28\n",
    "\n",
    "    plt.imshow(array, cmap=\"gray\")  # Display image in grayscale\n",
    "    plt.axis(\"off\")  # Hide axes\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "train_dataset = DigitDataset(dataFrame=df_train, targetColumn='label', transform=True)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = DigitDataset(dataFrame=df_val, targetColumn='label', transform=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_dataset = DigitDataset(dataFrame=df_test, targetColumn=None, transform=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dummy, y_dummy = next(iter(train_dataloader))\n",
    "array_to_image(x_dummy[0]), y_dummy[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'We have a total of {len(train_dataloader)} Batches in the Train Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "class BaseLineModel(nn.Module):\n",
    "    def __init__(self, input_features, hidden_units, out_features):\n",
    "        super().__init__()\n",
    "        self.layer_block_1 = nn.Sequential(\n",
    "            nn.Linear(input_features, hidden_units),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer_block_2 = nn.Sequential(\n",
    "            nn.Linear(hidden_units, hidden_units),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer_output = nn.Sequential(\n",
    "            nn.Linear(hidden_units, out_features),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.layer_block_1(x)\n",
    "        x = self.layer_block_2(x)\n",
    "        x = self.layer_output(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x_batch):\n",
    "        preds = []\n",
    "        for x in x_batch:\n",
    "            logits = self(x)\n",
    "            pred = torch.argmax(F.softmax(logits, dim=-1))\n",
    "            preds.append(pred)\n",
    "        return torch.tensor(preds, dtype=torch.int32)\n",
    "\n",
    "\n",
    "input_dim = x_dummy.shape[1]\n",
    "hidden_dim = 256\n",
    "output_dim = 10\n",
    "#b_model = BaseLineModel(input_dim, hidden_dim, output_dim)\n",
    "#b_model.predict(x_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomCNNModel(nn.Module):\n",
    "  def __init__(self, in_features, hidden_units, out_features):\n",
    "      super().__init__()\n",
    "      self.conv_block_1 = nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "           in_channels=in_features,\n",
    "           out_channels=hidden_units,\n",
    "           kernel_size=(3,3),\n",
    "           padding=1,\n",
    "           stride=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(\n",
    "           in_channels=hidden_units,\n",
    "           out_channels=hidden_units,\n",
    "           kernel_size=(3,3),\n",
    "           padding=1,\n",
    "           stride=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(\n",
    "           kernel_size=2,\n",
    "           stride=2 # Default Stride size is equal to Kernel Size)\n",
    "        )\n",
    "      )\n",
    "      self.conv_block_2 = nn.Sequential(\n",
    "        nn.Conv2d(\n",
    "           in_channels=hidden_units,\n",
    "           out_channels=hidden_units * 4,\n",
    "           kernel_size=(3,3),\n",
    "           padding=1,\n",
    "           stride=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(\n",
    "           in_channels=hidden_units * 4,\n",
    "           out_channels=hidden_units,\n",
    "           kernel_size=(3,3),\n",
    "           padding=1,\n",
    "           stride=1\n",
    "        ),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(\n",
    "           kernel_size=2,\n",
    "           stride=2 # Default Stride size is equal to Kernel Size)\n",
    "        )\n",
    "      )\n",
    "\n",
    "      self.clasifier = nn.Sequential(\n",
    "         nn.Flatten(),\n",
    "         nn.Linear(\n",
    "            # Calculate and set in_features, depending on the data shape.\n",
    "            # As the output of Thrid conv block has a shape of  torch.Size([32, 64, 28, 28]).\n",
    "            # We will simply multiply in_features value with 28 * 28.\n",
    "            in_features=hidden_units * 7 * 7,\n",
    "            out_features=out_features,\n",
    "          )\n",
    "      )\n",
    "\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    #print(f'Input Shape : {x.shape}')\n",
    "    x = self.conv_block_1(x)\n",
    "    #print(f'After First Conv Block Shape : {x.shape}')\n",
    "    x = self.conv_block_2(x)\n",
    "    #print(f'After Second Conv Block Shape : {x.shape}')\n",
    "    x = self.clasifier(x)\n",
    "    #print(f'After Classifier Shape : {x.shape}')\n",
    "    return x\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = CustomCNNModel(1, hidden_dim, output_dim)\n",
    "cnn_model(x_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(),lr= 0.0001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = cnn_model(x_dummy)\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, dataloader, loss_fn, optimizer, device=device):\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.train()\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Forward Pass\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        logits = model(X)\n",
    "        loss = loss_fn(logits, y)\n",
    "        optimizer.zero_grad()\n",
    "        #print(logits.shape)\n",
    "        train_loss += loss.item()\n",
    "        pred = torch.argmax(F.softmax(logits, dim=-1), dim=-1)\n",
    "        #print(pred.shape)\n",
    "        train_acc += accuracy_score(y_true=y.to('cpu'), y_pred=pred.to('cpu'))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    return train_loss, train_acc\n",
    "\n",
    "def val_step(model, dataloader, loss_fn, device=device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            # Forward Pass\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            logits = model(X)\n",
    "            loss = loss_fn(logits, y)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            pred = torch.argmax(F.softmax(logits, dim=-1), dim=-1)\n",
    "            #print(pred.shape)\n",
    "            test_acc +=  accuracy_score(y_true=y.to('cpu'), y_pred=pred.to('cpu'))\n",
    "            \n",
    "\n",
    "        test_loss /= len(dataloader)\n",
    "        test_acc /= len(dataloader)\n",
    "        \n",
    "        return test_loss, test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau \n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min',patience=5)\n",
    "\n",
    "epochs = 100\n",
    "for epoch in range(1, epochs +1):\n",
    "    print(f'Epoch: {epoch}------\\n')\n",
    "    cnn_model = cnn_model.to(device)\n",
    "    train_loss , train_acc = train_step(cnn_model, train_dataloader, loss_fn, optimizer, device=device)\n",
    "    val_loss , val_acc = val_step(cnn_model, val_dataloader, loss_fn, device=device)\n",
    "    scheduler.step(val_loss)  # Adjust LR based on validation loss\n",
    "    print(f\"Training Loss: {train_loss} | Training Accuracy: {train_acc * 100:.2f}%\")\n",
    "    print(f\"Validation Loss: {val_loss} | Validation Accuracy: {val_acc * 100:.2f}%\")\n",
    "    print(f\"Current LR: {optimizer.param_groups[0]['lr']}\")  # Check the updated LR\n",
    "    torch.save(cnn_model.state_dict(),f'models/cnn_epoch_{epoch}.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best Performed Model\n",
    "#cnn_model = CustomCNNModel(1, hidden_dim, output_dim)\n",
    "#cnn_model.load_state_dict(torch.load('models/cnn_epoch_47.pth', weights_only=True, map_location='mps:0'))  # Choose \n",
    "#cnn_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predictTest(model: CustomCNNModel, dataloader):\n",
    "    preds = []\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X)  in enumerate(dataloader):\n",
    "            X = X.to(device)\n",
    "            logits = model(X)\n",
    "            pred = torch.argmax(F.softmax(logits, dim=-1), dim=-1)\n",
    "            preds.append(pred.to('cpu'))  # Append batch predictions\n",
    "    return np.concatenate(preds, axis=0).astype(int).tolist()  # Convert to int\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_loss, validation_accuracy = val_step(model=cnn_model, dataloader=val_dataloader, loss_fn=loss_fn, device=device)\n",
    "print(f'Validation Loss: {val_loss} | Validation Accuracy: {val_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test_pred = predictTest(model=cnn_model, dataloader=test_dataloader)\n",
    "df_results = pd.DataFrame({'Label': test_pred})\n",
    "\n",
    "df_results.index = df_results.index + 1\n",
    "df_results.index.name = 'ImageId'\n",
    "\n",
    "# Display the first few rows\n",
    "print(df_results.head())\n",
    "\n",
    "df_results.to_csv('cnn_results_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
