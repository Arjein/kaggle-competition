{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "device = 'mps'\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (300000, 11)\n",
      "Extra Train shape (3694318, 11)\n",
      "Combined Train shape (3994318, 11)\n",
      "Test shape (200000, 10)\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Brand",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Material",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Size",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Compartments",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Laptop Compartment",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Waterproof",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Style",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Color",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Weight Capacity (kg)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "21394a52-4e47-4865-8ab0-f42a12f3f7af",
       "rows": [
        [
         "0",
         "300000",
         "Puma",
         "Leather",
         "Small",
         "2.0",
         "No",
         "No",
         "Tote",
         "Green",
         "20.671146610744945"
        ],
        [
         "1",
         "300001",
         "Nike",
         "Canvas",
         "Medium",
         "7.0",
         "No",
         "Yes",
         "Backpack",
         "Green",
         "13.564104570506816"
        ],
        [
         "2",
         "300002",
         "Adidas",
         "Canvas",
         "Large",
         "9.0",
         "No",
         "Yes",
         "Messenger",
         "Blue",
         "11.80979907832244"
        ],
        [
         "3",
         "300003",
         "Adidas",
         "Nylon",
         "Large",
         "1.0",
         "Yes",
         "No",
         "Messenger",
         "Green",
         "18.47703608562426"
        ],
        [
         "4",
         "300004",
         null,
         "Nylon",
         "Large",
         "2.0",
         "Yes",
         "Yes",
         "Tote",
         "Black",
         "9.90795303354249"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Material</th>\n",
       "      <th>Size</th>\n",
       "      <th>Compartments</th>\n",
       "      <th>Laptop Compartment</th>\n",
       "      <th>Waterproof</th>\n",
       "      <th>Style</th>\n",
       "      <th>Color</th>\n",
       "      <th>Weight Capacity (kg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000</td>\n",
       "      <td>Puma</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Small</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Tote</td>\n",
       "      <td>Green</td>\n",
       "      <td>20.671147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300001</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>Medium</td>\n",
       "      <td>7.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Backpack</td>\n",
       "      <td>Green</td>\n",
       "      <td>13.564105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300002</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>Large</td>\n",
       "      <td>9.0</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Blue</td>\n",
       "      <td>11.809799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300003</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>Nylon</td>\n",
       "      <td>Large</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>18.477036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nylon</td>\n",
       "      <td>Large</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Tote</td>\n",
       "      <td>Black</td>\n",
       "      <td>9.907953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id   Brand Material    Size  Compartments Laptop Compartment  \\\n",
       "0  300000    Puma  Leather   Small           2.0                 No   \n",
       "1  300001    Nike   Canvas  Medium           7.0                 No   \n",
       "2  300002  Adidas   Canvas   Large           9.0                 No   \n",
       "3  300003  Adidas    Nylon   Large           1.0                Yes   \n",
       "4  300004     NaN    Nylon   Large           2.0                Yes   \n",
       "\n",
       "  Waterproof      Style  Color  Weight Capacity (kg)  \n",
       "0         No       Tote  Green             20.671147  \n",
       "1        Yes   Backpack  Green             13.564105  \n",
       "2        Yes  Messenger   Blue             11.809799  \n",
       "3         No  Messenger  Green             18.477036  \n",
       "4        Yes       Tote  Black              9.907953  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "print(\"Train shape\", train.shape )\n",
    "train.head()\n",
    "train2 = pd.read_csv(\"data/training_extra.csv\")\n",
    "print(\"Extra Train shape\", train2.shape )\n",
    "train2.head()\n",
    "train = pd.concat([train,train2],axis=0,ignore_index=True)\n",
    "print(\"Combined Train shape\", train.shape)\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "print(\"Test shape\", test.shape )\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.insert(5,\"CWoutLaptop\", train['Compartments'] - (train['Laptop Compartment'] == 'Yes').astype(int))\n",
    "test.insert(5,\"CWoutLaptop\", test['Compartments'] - (test['Laptop Compartment'] == 'Yes').astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Brand",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Material",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Size",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Compartments",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "CWoutLaptop",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Laptop Compartment",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Waterproof",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Style",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Color",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Weight Capacity (kg)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Price",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "59fbe353-31dc-4e82-988c-24914ca78f0a",
       "rows": [
        [
         "0",
         "0",
         "Jansport",
         "Leather",
         "Medium",
         "7.0",
         "6.0",
         "Yes",
         "No",
         "Tote",
         "Black",
         "11.611722805222309",
         "112.15875"
        ],
        [
         "1",
         "1",
         "Jansport",
         "Canvas",
         "Small",
         "10.0",
         "9.0",
         "Yes",
         "Yes",
         "Messenger",
         "Green",
         "27.07853658053123",
         "68.88056"
        ],
        [
         "2",
         "2",
         "Under Armour",
         "Leather",
         "Small",
         "2.0",
         "1.0",
         "Yes",
         "No",
         "Messenger",
         "Red",
         "16.643759949103497",
         "39.1732"
        ],
        [
         "3",
         "3",
         "Nike",
         "Nylon",
         "Small",
         "8.0",
         "7.0",
         "Yes",
         "No",
         "Messenger",
         "Green",
         "12.937220306632067",
         "80.60793"
        ],
        [
         "4",
         "4",
         "Adidas",
         "Canvas",
         "Medium",
         "1.0",
         "0.0",
         "Yes",
         "Yes",
         "Messenger",
         "Green",
         "17.749338465908988",
         "86.02312"
        ],
        [
         "5",
         "5",
         "Nike",
         "Canvas",
         "Medium",
         "10.0",
         "10.0",
         "No",
         "Yes",
         null,
         "Black",
         "7.241812431393921",
         "20.01553"
        ],
        [
         "6",
         "6",
         "Nike",
         null,
         "Large",
         "3.0",
         "3.0",
         "No",
         "No",
         "Backpack",
         "Green",
         "6.82812289959413",
         "84.805"
        ],
        [
         "7",
         "7",
         "Puma",
         "Canvas",
         "Small",
         "1.0",
         "0.0",
         "Yes",
         "Yes",
         "Backpack",
         "Blue",
         "21.48886449943962",
         "27.15815"
        ],
        [
         "8",
         "8",
         "Under Armour",
         "Polyester",
         "Medium",
         "8.0",
         "7.0",
         "Yes",
         "No",
         "Tote",
         "Gray",
         "10.207780204196547",
         "25.98652"
        ],
        [
         "9",
         "9",
         "Under Armour",
         "Nylon",
         "Medium",
         "2.0",
         "1.0",
         "Yes",
         "Yes",
         "Messenger",
         "Pink",
         "15.895100441539512",
         "38.48741"
        ],
        [
         "10",
         "10",
         "Nike",
         "Polyester",
         "Large",
         "1.0",
         "0.0",
         "Yes",
         "No",
         "Backpack",
         null,
         "27.80695093142625",
         "68.31047"
        ],
        [
         "11",
         "11",
         "Nike",
         "Polyester",
         null,
         "10.0",
         "10.0",
         "No",
         "No",
         null,
         "Gray",
         "13.697553716032546",
         "23.25963"
        ],
        [
         "12",
         "12",
         "Adidas",
         "Nylon",
         "Medium",
         "5.0",
         "4.0",
         "Yes",
         "No",
         "Backpack",
         "Blue",
         "15.872049592139104",
         "111.80791"
        ],
        [
         "13",
         "13",
         "Under Armour",
         "Leather",
         "Medium",
         "8.0",
         "8.0",
         "No",
         "No",
         "Tote",
         "Red",
         "26.07940932802842",
         "26.37209"
        ],
        [
         "14",
         "14",
         "Nike",
         "Polyester",
         "Small",
         "10.0",
         "10.0",
         "No",
         "Yes",
         "Tote",
         "Green",
         "14.744146515842305",
         "75.96081"
        ],
        [
         "15",
         "15",
         "Adidas",
         "Leather",
         "Small",
         "10.0",
         "9.0",
         "Yes",
         "No",
         "Tote",
         "Green",
         "7.934018057756724",
         "37.78611"
        ],
        [
         "16",
         "16",
         "Puma",
         "Polyester",
         "Large",
         "2.0",
         "2.0",
         "No",
         "Yes",
         "Backpack",
         "Blue",
         "18.98877353521776",
         "69.61682"
        ],
        [
         "17",
         "17",
         "Puma",
         "Nylon",
         "Large",
         "1.0",
         "1.0",
         "No",
         "Yes",
         "Tote",
         "Gray",
         "15.533610728685636",
         "68.24736"
        ],
        [
         "18",
         "18",
         "Nike",
         "Canvas",
         "Small",
         "5.0",
         "5.0",
         "No",
         "No",
         "Messenger",
         "Black",
         "26.11608101874347",
         "59.10262"
        ],
        [
         "19",
         "19",
         "Adidas",
         "Canvas",
         "Small",
         "3.0",
         "3.0",
         "No",
         "Yes",
         "Tote",
         "Green",
         "26.262636968992748",
         "59.18372"
        ],
        [
         "20",
         "20",
         "Adidas",
         "Leather",
         "Small",
         "3.0",
         "2.0",
         "Yes",
         "Yes",
         "Messenger",
         "Blue",
         "28.56090480210274",
         "112.27855"
        ],
        [
         "21",
         "21",
         "Under Armour",
         "Polyester",
         null,
         "9.0",
         "8.0",
         "Yes",
         "Yes",
         "Messenger",
         "Gray",
         "11.219051842888511",
         "35.46348"
        ],
        [
         "22",
         "22",
         "Puma",
         "Nylon",
         "Large",
         "7.0",
         "6.0",
         "Yes",
         null,
         "Backpack",
         "Gray",
         "17.181181857150946",
         "132.68502"
        ],
        [
         "23",
         "23",
         "Jansport",
         "Leather",
         "Medium",
         "1.0",
         "0.0",
         "Yes",
         "No",
         "Tote",
         "Blue",
         "12.571250463424535",
         "106.83635"
        ],
        [
         "24",
         "24",
         "Jansport",
         "Nylon",
         "Large",
         "1.0",
         "1.0",
         "No",
         "No",
         "Backpack",
         "Red",
         "25.936885828229464",
         "80.95478"
        ],
        [
         "25",
         "25",
         "Adidas",
         "Nylon",
         "Medium",
         "2.0",
         "2.0",
         "No",
         "No",
         "Messenger",
         "Green",
         "22.89880858620618",
         "90.80347"
        ],
        [
         "26",
         "26",
         "Adidas",
         "Leather",
         "Medium",
         "5.0",
         "4.0",
         "Yes",
         "Yes",
         "Messenger",
         "Pink",
         "10.68532941500023",
         "62.85374"
        ],
        [
         "27",
         "27",
         "Jansport",
         "Canvas",
         "Medium",
         "10.0",
         "10.0",
         "No",
         "No",
         "Backpack",
         "Pink",
         "6.513475793894409",
         "96.79852"
        ],
        [
         "28",
         "28",
         "Under Armour",
         "Nylon",
         "Small",
         "6.0",
         "5.0",
         "Yes",
         "Yes",
         "Messenger",
         "Green",
         "7.58495663865031",
         "49.09326"
        ],
        [
         "29",
         "29",
         "Under Armour",
         "Canvas",
         "Small",
         "7.0",
         "6.0",
         "Yes",
         "No",
         "Messenger",
         "Red",
         "25.07246672669807",
         "107.47541"
        ],
        [
         "30",
         "30",
         null,
         "Leather",
         "Large",
         "3.0",
         "3.0",
         "No",
         "Yes",
         "Tote",
         "Blue",
         "21.304433771546968",
         "138.32699"
        ],
        [
         "31",
         "31",
         "Nike",
         "Canvas",
         "Medium",
         "7.0",
         "7.0",
         "No",
         "Yes",
         "Backpack",
         "Gray",
         "24.66576555637821",
         "40.42064"
        ],
        [
         "32",
         "32",
         "Puma",
         "Leather",
         "Medium",
         "2.0",
         "1.0",
         "Yes",
         "Yes",
         "Backpack",
         "Blue",
         "28.81224495305761",
         "107.38007"
        ],
        [
         "33",
         "33",
         "Puma",
         "Leather",
         "Medium",
         "10.0",
         "9.0",
         "Yes",
         "Yes",
         "Tote",
         "Gray",
         "29.30014343223143",
         "56.26168"
        ],
        [
         "34",
         "34",
         "Under Armour",
         "Canvas",
         "Large",
         "4.0",
         "4.0",
         "No",
         "No",
         "Tote",
         "Green",
         "8.14986019761506",
         "22.55705"
        ],
        [
         "35",
         "35",
         "Puma",
         "Nylon",
         "Small",
         "2.0",
         "1.0",
         "Yes",
         "No",
         "Backpack",
         "Gray",
         "13.948292897732696",
         "128.8738"
        ],
        [
         "36",
         "36",
         "Adidas",
         "Canvas",
         "Large",
         "3.0",
         "2.0",
         "Yes",
         "No",
         "Messenger",
         "Black",
         "18.72640035119508",
         "86.30284"
        ],
        [
         "37",
         "37",
         "Under Armour",
         "Canvas",
         "Medium",
         "10.0",
         "9.0",
         "Yes",
         "No",
         "Messenger",
         "Red",
         "14.928790515728585",
         "42.98934"
        ],
        [
         "38",
         "38",
         "Adidas",
         "Polyester",
         null,
         "5.0",
         "4.0",
         "Yes",
         "Yes",
         "Messenger",
         "Black",
         "21.547849374024693",
         "53.54452"
        ],
        [
         "39",
         "39",
         "Adidas",
         "Nylon",
         "Large",
         "4.0",
         "3.0",
         "Yes",
         "Yes",
         "Backpack",
         "Black",
         "10.795253384817736",
         "58.94535"
        ],
        [
         "40",
         "40",
         "Adidas",
         "Leather",
         "Medium",
         "5.0",
         "5.0",
         "No",
         "No",
         "Backpack",
         "Red",
         "6.127826388847283",
         "72.50358"
        ],
        [
         "41",
         "41",
         "Puma",
         "Nylon",
         "Medium",
         "9.0",
         "8.0",
         "Yes",
         "Yes",
         "Messenger",
         "Blue",
         "7.16305043894184",
         "138.54097"
        ],
        [
         "42",
         "42",
         "Adidas",
         "Leather",
         "Medium",
         "9.0",
         "9.0",
         "No",
         "No",
         "Messenger",
         "Black",
         "18.66939632959737",
         "78.93463"
        ],
        [
         "43",
         "43",
         "Under Armour",
         "Leather",
         "Medium",
         "2.0",
         "1.0",
         "Yes",
         "Yes",
         "Tote",
         "Black",
         "15.611181129419718",
         "36.62238"
        ],
        [
         "44",
         "44",
         "Nike",
         "Leather",
         "Large",
         "7.0",
         "7.0",
         "No",
         "Yes",
         "Backpack",
         "Red",
         "15.62478714406082",
         "102.84689"
        ],
        [
         "45",
         "45",
         "Adidas",
         "Canvas",
         "Medium",
         "7.0",
         "7.0",
         "No",
         "Yes",
         "Backpack",
         "Gray",
         "22.33118435588429",
         "137.3204"
        ],
        [
         "46",
         "46",
         "Puma",
         "Leather",
         "Small",
         "6.0",
         "5.0",
         "Yes",
         "No",
         "Messenger",
         "Blue",
         "24.99010340333541",
         "20.51106"
        ],
        [
         "47",
         "47",
         "Under Armour",
         "Nylon",
         "Small",
         "1.0",
         "1.0",
         "No",
         "Yes",
         "Backpack",
         "Black",
         "29.75241328765672",
         "62.98114"
        ],
        [
         "48",
         "48",
         null,
         "Canvas",
         "Medium",
         "2.0",
         "2.0",
         "No",
         "No",
         "Tote",
         null,
         "5.0",
         "42.28337"
        ],
        [
         "49",
         "49",
         "Under Armour",
         "Leather",
         "Small",
         "6.0",
         "5.0",
         "Yes",
         "No",
         "Backpack",
         "Gray",
         "22.057555016750868",
         "49.65398"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 3994318
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Material</th>\n",
       "      <th>Size</th>\n",
       "      <th>Compartments</th>\n",
       "      <th>CWoutLaptop</th>\n",
       "      <th>Laptop Compartment</th>\n",
       "      <th>Waterproof</th>\n",
       "      <th>Style</th>\n",
       "      <th>Color</th>\n",
       "      <th>Weight Capacity (kg)</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Jansport</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Medium</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Tote</td>\n",
       "      <td>Black</td>\n",
       "      <td>11.611723</td>\n",
       "      <td>112.15875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jansport</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>Small</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>27.078537</td>\n",
       "      <td>68.88056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Under Armour</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Small</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Red</td>\n",
       "      <td>16.643760</td>\n",
       "      <td>39.17320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Nylon</td>\n",
       "      <td>Small</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>12.937220</td>\n",
       "      <td>80.60793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>Medium</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Green</td>\n",
       "      <td>17.749338</td>\n",
       "      <td>86.02312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994313</th>\n",
       "      <td>4194313</td>\n",
       "      <td>Nike</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Messenger</td>\n",
       "      <td>Blue</td>\n",
       "      <td>28.098120</td>\n",
       "      <td>104.74460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994314</th>\n",
       "      <td>4194314</td>\n",
       "      <td>Puma</td>\n",
       "      <td>Leather</td>\n",
       "      <td>Small</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Tote</td>\n",
       "      <td>Blue</td>\n",
       "      <td>17.379531</td>\n",
       "      <td>122.39043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994315</th>\n",
       "      <td>4194315</td>\n",
       "      <td>Jansport</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>Large</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Backpack</td>\n",
       "      <td>Red</td>\n",
       "      <td>17.037708</td>\n",
       "      <td>148.18470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994316</th>\n",
       "      <td>4194316</td>\n",
       "      <td>Puma</td>\n",
       "      <td>Canvas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Backpack</td>\n",
       "      <td>Gray</td>\n",
       "      <td>28.783339</td>\n",
       "      <td>22.32269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994317</th>\n",
       "      <td>4194317</td>\n",
       "      <td>Under Armour</td>\n",
       "      <td>Polyester</td>\n",
       "      <td>Medium</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Backpack</td>\n",
       "      <td>Blue</td>\n",
       "      <td>23.076169</td>\n",
       "      <td>107.61199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3994318 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id         Brand   Material    Size  Compartments  CWoutLaptop  \\\n",
       "0              0      Jansport    Leather  Medium           7.0          6.0   \n",
       "1              1      Jansport     Canvas   Small          10.0          9.0   \n",
       "2              2  Under Armour    Leather   Small           2.0          1.0   \n",
       "3              3          Nike      Nylon   Small           8.0          7.0   \n",
       "4              4        Adidas     Canvas  Medium           1.0          0.0   \n",
       "...          ...           ...        ...     ...           ...          ...   \n",
       "3994313  4194313          Nike     Canvas     NaN           3.0          2.0   \n",
       "3994314  4194314          Puma    Leather   Small          10.0          9.0   \n",
       "3994315  4194315      Jansport     Canvas   Large          10.0         10.0   \n",
       "3994316  4194316          Puma     Canvas     NaN           2.0          2.0   \n",
       "3994317  4194317  Under Armour  Polyester  Medium           2.0          1.0   \n",
       "\n",
       "        Laptop Compartment Waterproof      Style  Color  Weight Capacity (kg)  \\\n",
       "0                      Yes         No       Tote  Black             11.611723   \n",
       "1                      Yes        Yes  Messenger  Green             27.078537   \n",
       "2                      Yes         No  Messenger    Red             16.643760   \n",
       "3                      Yes         No  Messenger  Green             12.937220   \n",
       "4                      Yes        Yes  Messenger  Green             17.749338   \n",
       "...                    ...        ...        ...    ...                   ...   \n",
       "3994313                Yes        Yes  Messenger   Blue             28.098120   \n",
       "3994314                Yes        Yes       Tote   Blue             17.379531   \n",
       "3994315                 No         No   Backpack    Red             17.037708   \n",
       "3994316                 No         No   Backpack   Gray             28.783339   \n",
       "3994317                Yes         No   Backpack   Blue             23.076169   \n",
       "\n",
       "             Price  \n",
       "0        112.15875  \n",
       "1         68.88056  \n",
       "2         39.17320  \n",
       "3         80.60793  \n",
       "4         86.02312  \n",
       "...            ...  \n",
       "3994313  104.74460  \n",
       "3994314  122.39043  \n",
       "3994315  148.18470  \n",
       "3994316   22.32269  \n",
       "3994317  107.61199  \n",
       "\n",
       "[3994318 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c_/jxz3szl16zbcx94x257l4skc0000gn/T/ipykernel_51863/3482969793.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train[\"Weight Capacity (kg)\"].fillna(train[\"Weight Capacity (kg)\"].median(), inplace=True)\n",
      "/var/folders/c_/jxz3szl16zbcx94x257l4skc0000gn/T/ipykernel_51863/3482969793.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test[\"Weight Capacity (kg)\"].fillna(test[\"Weight Capacity (kg)\"].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train[\"Weight Capacity (kg)\"].fillna(train[\"Weight Capacity (kg)\"].median(), inplace=True)\n",
    "test[\"Weight Capacity (kg)\"].fillna(test[\"Weight Capacity (kg)\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 categorical columns:\n",
      "['Brand', 'Material', 'Size', 'Compartments', 'CWoutLaptop', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']\n",
      "There are 1 numerical column:\n",
      "['Weight Capacity (kg)']\n"
     ]
    }
   ],
   "source": [
    "CATS = list(train.columns[1:-2])\n",
    "print(f\"There are {len(CATS)} categorical columns:\")\n",
    "print( CATS )\n",
    "print(f\"There are 1 numerical column:\")\n",
    "print( [\"Weight Capacity (kg)\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We engineer 8 new columns!\n",
      "['Brand_wc', 'Material_wc', 'Size_wc', 'Compartments_wc', 'Laptop Compartment_wc', 'Waterproof_wc', 'Style_wc', 'Color_wc']\n"
     ]
    }
   ],
   "source": [
    "COMBO = []\n",
    "for i,c in enumerate(CATS):\n",
    "    combine = pd.concat([train[c],test[c]],axis=0)\n",
    "    combine,_ = pd.factorize(combine)\n",
    "    train[c] = combine[:len(train)]\n",
    "    test[c] = combine[len(train):]\n",
    "    n = f\"{c}_wc\"\n",
    "    train[n] = train[c]*100 + train[\"Weight Capacity (kg)\"]\n",
    "    test[n] = test[c]*100 + test[\"Weight Capacity (kg)\"]\n",
    "    COMBO.append(n)\n",
    "print()\n",
    "print(f\"We engineer {len(COMBO)} new columns!\")\n",
    "print( COMBO )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We now have 17 columns:\n",
      "['Brand', 'Material', 'Size', 'Compartments', 'Laptop Compartment', 'Waterproof', 'Style', 'Color', 'Weight Capacity (kg)', 'Brand_wc', 'Material_wc', 'Size_wc', 'Compartments_wc', 'Laptop Compartment_wc', 'Waterproof_wc', 'Style_wc', 'Color_wc']\n"
     ]
    }
   ],
   "source": [
    "FEATURES = CATS + [\"Weight Capacity (kg)\"] + COMBO\n",
    "print(f\"We now have {len(FEATURES)} columns:\")\n",
    "print( FEATURES )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STATISTICS TO AGGEGATE FOR OUR FEATURE GROUPS\n",
    "STATS = [\"mean\", \"std\", \"count\", \"nunique\", \"median\", \"min\", \"max\", \"skew\", \"range\"]\n",
    "# Added Mode\n",
    "STATS2 = [\"mean\", \"std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def impute_dataset(df, cols):\n",
    "    fill_values = {}\n",
    "\n",
    "    for col in cols:\n",
    "        if \"mean\" in col:  \n",
    "            fill_values[col] = df[col].mean()  # Mean for these stats\n",
    "        elif \"median\" in col:  \n",
    "            fill_values[col] = df[col].median()  # Median for these stats\n",
    "        elif \"count\" in col or \"nunique\" in col:  \n",
    "            fill_values[col] = 0  # 0 for count-based stats\n",
    "        elif \"min\" in col:  \n",
    "            fill_values[col] = df[col].min()\n",
    "        elif \"max\" in col:  \n",
    "            fill_values[col] = df[col].max()\n",
    "        elif \"range\" in col:  \n",
    "            fill_values[col] = df[col].max() - df[col].min()\n",
    "        elif \"std\" in col or \"skew\" in col:  \n",
    "            fill_values[col] = 0  # Std/Skew might be NaN if only 1 value, fill with 0\n",
    "\n",
    "    df.fillna(fill_values, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class NeuralNetwEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_sizes, num_numerical, hidden_units, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        # Embedding layers for categorical features\n",
    "        self.embeddings = nn.ModuleList([\n",
    "            nn.Embedding(num_categories, embedding_dim)\n",
    "            for num_categories, embedding_dim in embedding_sizes.values()\n",
    "        ])\n",
    "        \n",
    "        # Compute total embedding output size\n",
    "        total_embedding_size = sum([embedding_dim for _, embedding_dim in embedding_sizes.values()])\n",
    "        \n",
    "        # Define MLP layers\n",
    "        input_dim = total_embedding_size + num_numerical\n",
    "        self.layer_1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_units),\n",
    "            nn.BatchNorm1d(hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "        \n",
    "        self.layer_2 = nn.Sequential(\n",
    "            nn.Linear(hidden_units, hidden_units * 4),\n",
    "            nn.BatchNorm1d(hidden_units * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "\n",
    "        self.layer_3 = nn.Sequential(\n",
    "            nn.Linear(hidden_units * 4, hidden_units),\n",
    "            nn.BatchNorm1d(hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(hidden_units, output_dim)\n",
    "\n",
    "        # Store number of categorical features\n",
    "        self.num_categorical = len(embedding_sizes)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Split input tensor into categorical and numerical parts\n",
    "        x_categorical = X[:, :self.num_categorical].long()  # First columns (categorical)\n",
    "        x_numerical = X[:, self.num_categorical:]           # Remaining columns (numerical)\n",
    "\n",
    "        # Convert categorical features to embeddings\n",
    "        x_embedded = [emb(x_categorical[:, i]) for i, emb in enumerate(self.embeddings)]\n",
    "        x_embedded = torch.cat(x_embedded, dim=1)  # Concatenate embeddings\n",
    "        \n",
    "        # Concatenate embeddings with numerical features\n",
    "        x = torch.cat([x_embedded, x_numerical], dim=1)\n",
    "        \n",
    "        # Pass through MLP layers\n",
    "        x = self.layer_1(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.layer_3(x)\n",
    "        x = self.output_layer(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(m.weight, a=0.01, mode='fan_in', nonlinearity='leaky_relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackpackDataset(Dataset):\n",
    "    def __init__(self, df, isTest= False):\n",
    "        self.isTest = isTest\n",
    "        if not self.isTest:\n",
    "            self.X = torch.tensor(df.drop(columns=['Price']).values, dtype=torch.float32)  # Features\n",
    "            self.y = torch.tensor(df['Price'].values, dtype=torch.float32)  # Target\n",
    "        else:\n",
    "            self.X = torch.tensor(df.values, dtype= torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if not self.isTest:\n",
    "            return self.X[idx], self.y[idx]\n",
    "        else:\n",
    "            return self.X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Brand': (6, 2),\n",
       " 'Material': (5, 2),\n",
       " 'Size': (4, 2),\n",
       " 'Compartments': (10, 3),\n",
       " 'Laptop Compartment': (3, 2),\n",
       " 'Waterproof': (3, 2),\n",
       " 'Style': (4, 2),\n",
       " 'Color': (7, 2)}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_sizes = {col: (train[col].nunique(), min(50, max(2, int(np.sqrt(train[col].nunique())))))\n",
    "                   for col in CATS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "# Training the Network\n",
    "def train_step(dataloader, model, loss_fn, optimizer, metrics_fn):\n",
    "    model.train()\n",
    "    train_loss, train_rmse = 0, 0\n",
    "    \n",
    "    for batch, (X_b, y_b) in enumerate(dataloader):\n",
    "        X_b, y_b = X_b.to(device), y_b.to(device)\n",
    "        # Forward Pass\n",
    "        y_pred = model(X_b).squeeze()\n",
    "        # Loss\n",
    "        loss = loss_fn(y_pred, y_b)\n",
    "        e = metrics_fn(y_pred.to('cpu').detach(), y_b.to('cpu'))\n",
    "        train_loss += loss.item()\n",
    "        train_rmse += e\n",
    "        # Zero grad\n",
    "        optimizer.zero_grad()\n",
    "        # Backprop\n",
    "        loss.backward()\n",
    "        # Optimizer Step\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print(f'Train Loss ({batch}): {loss}')\n",
    "\n",
    "    train_loss /= len(dataloader)\n",
    "    train_rmse /= len(dataloader)\n",
    "\n",
    "    return train_loss, train_rmse\n",
    "\n",
    "def val_step(dataloader, model, loss_fn, metrics_fn):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_rmse = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X_b, y_b) in enumerate(dataloader):\n",
    "            X_b, y_b = X_b.to(device), y_b.to(device)\n",
    "            y_pred = model(X_b).squeeze()\n",
    "            val_loss += loss_fn(y_pred, y_b).item()\n",
    "            val_rmse += metrics_fn(y_pred.to('cpu').detach(), y_b.to('cpu'))\n",
    "        \n",
    "        val_loss /= len(dataloader)\n",
    "        val_rmse /= len(dataloader)\n",
    "\n",
    "    return val_loss, val_rmse\n",
    "\n",
    "\n",
    "def train_model(save_i,epochs,model, scheduler, loss_fn, optimizer, train_loader, val_loader):\n",
    "    for epoch in tqdm(range(1, epochs + 1)):\n",
    "        print(f'Epoch {epoch}: ----- |  Learning Rate: {scheduler.optimizer.param_groups[0]['lr']}\\n')\n",
    "        train_loss, train_rmse = train_step(dataloader=train_loader, model=model, loss_fn=loss_fn, optimizer=optimizer, metrics_fn=root_mean_squared_error)\n",
    "        val_loss, val_rmse = val_step(dataloader=val_loader, model=model, loss_fn=loss_fn,  metrics_fn=root_mean_squared_error)\n",
    "        print(f'Train Loss: {train_loss} | Validation Loss: {val_loss}')\n",
    "        print(f'Train RMSE: {train_rmse} | Validation RMSE: {val_rmse}')\n",
    "            # Step the scheduler based on validation loss at the end of each epoch\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        print('Saving Model')\n",
    "        torch.save(model.state_dict(), f\"models/model_checkpoint_{save_i}_{epoch}.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        return torch.sqrt(self.mse(yhat,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.state_dict of NeuralNetwEmbedding(\n",
      "  (embeddings): ModuleList(\n",
      "    (0): Embedding(6, 2)\n",
      "    (1): Embedding(5, 2)\n",
      "    (2): Embedding(4, 2)\n",
      "    (3): Embedding(10, 3)\n",
      "    (4-5): 2 x Embedding(3, 2)\n",
      "    (6): Embedding(4, 2)\n",
      "    (7): Embedding(7, 2)\n",
      "  )\n",
      "  (layer_1): Sequential(\n",
      "    (0): Linear(in_features=66, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (layer_2): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (layer_3): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      "  (output_layer): Linear(in_features=64, out_features=1, bias=True)\n",
      ")>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arjein/Documents/GitHub/kaggle/kaggle-competition/.venv/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "BATCH_SIZE= 64\n",
    "FOLDS = 10\n",
    "kf = KFold(n_splits=FOLDS, shuffle=True, random_state=1337)\n",
    "oof = np.zeros((len(train)))\n",
    "pred = np.zeros((len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, dataframe):\n",
    "    model.eval()\n",
    "    test_dataset = BackpackDataset(dataframe, isTest=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    preds = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X) in enumerate(test_loader):\n",
    "            X = X.to(device)\n",
    "            pred = model(X).squeeze()\n",
    "            preds.append(pred.to('cpu').numpy())\n",
    "    \n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### OUTER Fold 1 ###\n",
      " ## INNER Fold 1 (outer fold 1) ##\n",
      " ## INNER Fold 2 (outer fold 1) ##\n",
      " ## INNER Fold 3 (outer fold 1) ##\n",
      " ## INNER Fold 4 (outer fold 1) ##\n",
      " ## INNER Fold 5 (outer fold 1) ##\n",
      " ## INNER Fold 6 (outer fold 1) ##\n",
      " ## INNER Fold 7 (outer fold 1) ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: ----- |  Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [06:14<24:57, 374.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1593.5727767294006 | Validation Loss: 1500.851268735794\n",
      "Train RMSE: 39.661936145046276 | Validation RMSE: 38.67678580333278\n",
      "Saving Model\n",
      "Epoch 5: ----- |  Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [12:27<18:41, 373.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1525.6680226486433 | Validation Loss: 1500.5667083795\n",
      "Train RMSE: 38.99193993351677 | Validation RMSE: 38.67354315176984\n",
      "Saving Model\n",
      "Epoch 5: ----- |  Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [18:41<12:27, 373.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1521.5936118026511 | Validation Loss: 1498.5764703968814\n",
      "Train RMSE: 38.93968092889664 | Validation RMSE: 38.64716214394373\n",
      "Saving Model\n",
      "Epoch 5: ----- |  Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [24:54<06:13, 373.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1519.130942263517 | Validation Loss: 1497.2672742772604\n",
      "Train RMSE: 38.90899720150025 | Validation RMSE: 38.630103561738785\n",
      "Saving Model\n",
      "Epoch 5: ----- |  Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [31:11<00:00, 374.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1517.5672818425348 | Validation Loss: 1496.8401496240301\n",
      "Train RMSE: 38.88918227270167 | Validation RMSE: 38.62445239239136\n",
      "Saving Model\n",
      "### OUTER Fold 2 ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ## INNER Fold 1 (outer fold 2) ##\n",
      " ## INNER Fold 2 (outer fold 2) ##\n",
      " ## INNER Fold 3 (outer fold 2) ##\n",
      " ## INNER Fold 4 (outer fold 2) ##\n",
      " ## INNER Fold 5 (outer fold 2) ##\n",
      " ## INNER Fold 6 (outer fold 2) ##\n",
      " ## INNER Fold 7 (outer fold 2) ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: ----- |  Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [06:13<24:53, 373.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1515.8483657038264 | Validation Loss: 1499.7557652551745\n",
      "Train RMSE: 38.86675049608111 | Validation RMSE: 38.66263202609092\n",
      "Saving Model\n",
      "Epoch 10: ----- |  Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [12:27<18:41, 373.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1514.0609518843808 | Validation Loss: 1498.8533770773859\n",
      "Train RMSE: 38.84362744176216 | Validation RMSE: 38.65055749110075\n",
      "Saving Model\n",
      "Epoch 10: ----- |  Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [18:42<12:28, 374.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1512.8071201906907 | Validation Loss: 1498.473057736191\n",
      "Train RMSE: 38.828113677984895 | Validation RMSE: 38.64633744294238\n",
      "Saving Model\n",
      "Epoch 10: ----- |  Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [24:56<06:14, 374.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1511.8233892441651 | Validation Loss: 1498.5560029527435\n",
      "Train RMSE: 38.81589952416872 | Validation RMSE: 38.64733131930768\n",
      "Saving Model\n",
      "Epoch 10: ----- |  Learning Rate: 0.001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [31:09<00:00, 373.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1510.4230663196306 | Validation Loss: 1498.3721206206385\n",
      "Train RMSE: 38.79853399836957 | Validation RMSE: 38.64484017284319\n",
      "Saving Model\n",
      "### OUTER Fold 3 ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ## INNER Fold 1 (outer fold 3) ##\n",
      " ## INNER Fold 2 (outer fold 3) ##\n",
      " ## INNER Fold 3 (outer fold 3) ##\n",
      " ## INNER Fold 4 (outer fold 3) ##\n",
      " ## INNER Fold 5 (outer fold 3) ##\n",
      " ## INNER Fold 6 (outer fold 3) ##\n",
      " ## INNER Fold 7 (outer fold 3) ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: ----- |  Learning Rate: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [06:14<24:56, 374.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1509.4802668191971 | Validation Loss: 1497.8574135644706\n",
      "Train RMSE: 38.785429895442434 | Validation RMSE: 38.63754596582987\n",
      "Saving Model\n",
      "Epoch 15: ----- |  Learning Rate: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [12:29<18:44, 374.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1509.2372537792326 | Validation Loss: 1497.4135083095437\n",
      "Train RMSE: 38.783111209155415 | Validation RMSE: 38.63137222715112\n",
      "Saving Model\n",
      "Epoch 15: ----- |  Learning Rate: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [18:43<12:28, 374.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1509.3275217427363 | Validation Loss: 1497.5926902500596\n",
      "Train RMSE: 38.784388412674694 | Validation RMSE: 38.63401756018959\n",
      "Saving Model\n",
      "Epoch 15: ----- |  Learning Rate: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [24:57<06:14, 374.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1509.0712462468446 | Validation Loss: 1497.484928567509\n",
      "Train RMSE: 38.78066302374611 | Validation RMSE: 38.63252367600464\n",
      "Saving Model\n",
      "Epoch 15: ----- |  Learning Rate: 0.0001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [31:01<00:00, 372.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1508.8027136180724 | Validation Loss: 1497.5004780950328\n",
      "Train RMSE: 38.775964025241784 | Validation RMSE: 38.632716073828185\n",
      "Saving Model\n",
      "### OUTER Fold 4 ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ## INNER Fold 1 (outer fold 4) ##\n",
      " ## INNER Fold 2 (outer fold 4) ##\n",
      " ## INNER Fold 3 (outer fold 4) ##\n",
      " ## INNER Fold 4 (outer fold 4) ##\n",
      " ## INNER Fold 5 (outer fold 4) ##\n",
      " ## INNER Fold 6 (outer fold 4) ##\n",
      " ## INNER Fold 7 (outer fold 4) ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: ----- |  Learning Rate: 1e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [06:02<24:08, 362.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1508.5312658475086 | Validation Loss: 1497.0801971148032\n",
      "Train RMSE: 38.77342827103147 | Validation RMSE: 38.6278348757356\n",
      "Saving Model\n",
      "Epoch 20: ----- |  Learning Rate: 1e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [12:01<18:01, 360.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1508.6391107368954 | Validation Loss: 1497.0032304205024\n",
      "Train RMSE: 38.775174441761095 | Validation RMSE: 38.626716484298704\n",
      "Saving Model\n",
      "Epoch 20: ----- |  Learning Rate: 1e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [21:36<15:16, 458.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1508.6032141846215 | Validation Loss: 1496.93081610959\n",
      "Train RMSE: 38.774390849537035 | Validation RMSE: 38.62573979541472\n",
      "Saving Model\n",
      "Epoch 20: ----- |  Learning Rate: 1e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [27:34<06:58, 418.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1508.6593313911703 | Validation Loss: 1496.9920601449028\n",
      "Train RMSE: 38.77595597638609 | Validation RMSE: 38.62629080403833\n",
      "Saving Model\n",
      "Epoch 20: ----- |  Learning Rate: 1e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [33:33<00:00, 402.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1508.6584320775735 | Validation Loss: 1497.313758264801\n",
      "Train RMSE: 38.7755385050867 | Validation RMSE: 38.63086409751148\n",
      "Saving Model\n",
      "### OUTER Fold 5 ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ## INNER Fold 1 (outer fold 5) ##\n",
      " ## INNER Fold 2 (outer fold 5) ##\n",
      " ## INNER Fold 3 (outer fold 5) ##\n",
      " ## INNER Fold 4 (outer fold 5) ##\n",
      " ## INNER Fold 5 (outer fold 5) ##\n",
      " ## INNER Fold 6 (outer fold 5) ##\n",
      " ## INNER Fold 7 (outer fold 5) ##\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: ----- |  Learning Rate: 1.0000000000000002e-06\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [03:21<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 80\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_i\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_w_emb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 51\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(save_i, epochs, model, scheduler, loss_fn, optimizer, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_i\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m5\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: ----- |  Learning Rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscheduler\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 51\u001b[0m     train_loss, train_rmse \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroot_mean_squared_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     val_loss, val_rmse \u001b[38;5;241m=\u001b[39m val_step(dataloader\u001b[38;5;241m=\u001b[39mval_loader, model\u001b[38;5;241m=\u001b[39mmodel, loss_fn\u001b[38;5;241m=\u001b[39mloss_fn,  metrics_fn\u001b[38;5;241m=\u001b[39mroot_mean_squared_error)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Validation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[25], line 13\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(dataloader, model, loss_fn, optimizer, metrics_fn)\u001b[0m\n\u001b[1;32m     11\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(X_b)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Loss\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m e \u001b[38;5;241m=\u001b[39m metrics_fn(y_pred\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach(), y_b\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     15\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/Documents/GitHub/kaggle/kaggle-competition/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/kaggle/kaggle-competition/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/GitHub/kaggle/kaggle-competition/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:608\u001b[0m, in \u001b[0;36mMSELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/kaggle/kaggle-competition/.venv/lib/python3.12/site-packages/torch/nn/functional.py:3792\u001b[0m, in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3789\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m   3791\u001b[0m expanded_input, expanded_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbroadcast_tensors(\u001b[38;5;28minput\u001b[39m, target)\n\u001b[0;32m-> 3792\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpanded_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpanded_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3794\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_preds = np.zeros(len(test))\n",
    "\n",
    "# OUTER K FOLD\n",
    "for i, (train_index, test_index) in enumerate(kf.split(train)):\n",
    "    print(f\"### OUTER Fold {i+1} ###\")\n",
    "\n",
    "    X_train = train.loc[train_index,FEATURES+['Price']].reset_index(drop=True).copy()\n",
    "    y_train = train.loc[train_index,'Price']\n",
    "\n",
    "    X_valid = train.loc[test_index,FEATURES].reset_index(drop=True).copy()\n",
    "    y_valid = train.loc[test_index,'Price']\n",
    "\n",
    "    X_test = test[FEATURES].reset_index(drop=True).copy()\n",
    "\n",
    "    # INNER K FOLD (TO PREVENT LEAKAGE WHEN USING PRICE)\n",
    "    kf2 = KFold(n_splits=FOLDS, shuffle=True, random_state=1337)   \n",
    "    for j, (train_index2, test_index2) in enumerate(kf2.split(X_train)):\n",
    "        print(f\" ## INNER Fold {j+1} (outer fold {i+1}) ##\")\n",
    "\n",
    "        X_train2 = X_train.loc[train_index2,FEATURES+['Price']].copy()\n",
    "        X_valid2 = X_train.loc[test_index2,FEATURES].copy()\n",
    "\n",
    "        ### FEATURE SET 1 (uses price) ###\n",
    "        col = \"Weight Capacity (kg)\"\n",
    "        tmp = X_train2.groupby(col).Price.agg(STATS)\n",
    "        tmp.columns = [f\"TE1_wc_{s}\" for s in STATS]\n",
    "        X_valid2 = X_valid2.merge(tmp, on=col, how=\"left\")\n",
    "        for c in tmp.columns:\n",
    "            X_train.loc[test_index2,c] = X_valid2[c].values\n",
    "\n",
    "        ### FEATURE SET 2 (uses price) ###\n",
    "        for col in COMBO:\n",
    "            tmp = X_train2.groupby(col).Price.agg(STATS2)\n",
    "            tmp.columns = [f\"TE2_{col}_{s}\" for s in STATS2]\n",
    "            X_valid2 = X_valid2.merge(tmp, on=col, how=\"left\")\n",
    "            for c in tmp.columns:\n",
    "                X_train.loc[test_index2,c] = X_valid2[c].values\n",
    "\n",
    "    ### FEATURE SET 1 (uses price) ###\n",
    "    col = \"Weight Capacity (kg)\"\n",
    "    tmp = X_train.groupby(col).Price.agg(STATS)\n",
    "    tmp.columns = [f\"TE1_wc_{s}\" for s in STATS]\n",
    "    X_valid = X_valid.merge(tmp, on=col, how=\"left\")\n",
    "    X_test = X_test.merge(tmp, on=col, how=\"left\")\n",
    "\n",
    "    ### FEATURE SET 2 (uses price) ###\n",
    "    for col in COMBO:\n",
    "        tmp = X_train.groupby(col).Price.agg(STATS2)\n",
    "        tmp.columns = [f\"TE2_{col}_{s}\" for s in STATS2]\n",
    "        X_valid = X_valid.merge(tmp, on=col, how=\"left\")\n",
    "        X_test = X_test.merge(tmp, on=col, how=\"left\")\n",
    "\n",
    "    ### FEATURE SET 3 (does not use price) ###\n",
    "    for col in CATS:\n",
    "        col2 = \"Weight Capacity (kg)\"\n",
    "        tmp = X_train.groupby(col)[col2].agg(STATS2)\n",
    "        tmp.columns = [f\"FE3_{col}_wc_{s}\" for s in STATS2]\n",
    "        X_train = X_train.merge(tmp, on=col, how=\"left\")\n",
    "        X_valid = X_valid.merge(tmp, on=col, how=\"left\")\n",
    "        X_test = X_test.merge(tmp, on=col, how=\"left\")\n",
    "\n",
    "    # CONVERT TO CATS SO XGBOOST RECOGNIZES THEM\n",
    "    X_train[CATS] = X_train[CATS].astype(\"category\")\n",
    "    X_valid[CATS] = X_valid[CATS].astype(\"category\")\n",
    "    X_test[CATS] = X_test[CATS].astype(\"category\")\n",
    "    \n",
    "    TE_COLUMNS = [col for col in X_train.columns if col.startswith(\"TE\")]  # Identify target-encoded columns\n",
    "    \n",
    "    df_train = X_train\n",
    "    X_valid['Price'] = y_valid.values\n",
    "    df_val = X_valid\n",
    "    \n",
    "    df_train = impute_dataset(df_train, cols=TE_COLUMNS)\n",
    "    df_val = impute_dataset(df_val, cols=TE_COLUMNS)\n",
    "    X_test = impute_dataset(X_test, cols=TE_COLUMNS)\n",
    "\n",
    "    train_dataset = BackpackDataset(df=df_train, isTest= False)\n",
    "    val_dataset = BackpackDataset(df=df_val, isTest=False)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    model_w_emb = NeuralNetwEmbedding(embedding_sizes=embedding_sizes, num_numerical=49, hidden_units=64,output_dim= 1)\n",
    "    model_w_emb = model_w_emb.to(device)\n",
    "    model_w_emb.apply(init_weights)\n",
    "    \n",
    "    \n",
    "    loss_fn = RMSELoss()\n",
    "    optimizer = torch.optim.Adam(model_w_emb.parameters(), lr=1e-3)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.05, patience=4, verbose=True)\n",
    "    epochs = 10\n",
    "    train_model(save_i=i, epochs=epochs, model=model_w_emb, scheduler=scheduler, loss_fn=loss_fn, optimizer=optimizer, train_loader=train_loader, val_loader=val_loader)\n",
    "    preds = make_predictions(model=model_w_emb,dataframe=X_test)\n",
    "    all_preds += preds\n",
    "\n",
    "all_preds /= FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "preds_nn_emb = make_predictions(model_w_emb, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Price",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d2841292-95a9-4e6e-ae91-dfc0e1955336",
       "rows": [
        [
         "0",
         "300000",
         "79.98979078020368"
        ],
        [
         "1",
         "300001",
         "83.24929918561664"
        ],
        [
         "2",
         "300002",
         "86.40660749162946"
        ],
        [
         "3",
         "300003",
         "76.55946459089007"
        ],
        [
         "4",
         "300004",
         "79.38423810686383"
        ],
        [
         "5",
         "300005",
         "83.1335688999721"
        ],
        [
         "6",
         "300006",
         "93.689455304827"
        ],
        [
         "7",
         "300007",
         "78.02837916782924"
        ],
        [
         "8",
         "300008",
         "76.67259434291294"
        ],
        [
         "9",
         "300009",
         "80.36477661132812"
        ],
        [
         "10",
         "300010",
         "81.68307059151786"
        ],
        [
         "11",
         "300011",
         "80.9227044241769"
        ],
        [
         "12",
         "300012",
         "81.66816057477679"
        ],
        [
         "13",
         "300013",
         "85.4232155936105"
        ],
        [
         "14",
         "300014",
         "81.02300153459821"
        ],
        [
         "15",
         "300015",
         "72.67362213134766"
        ],
        [
         "16",
         "300016",
         "82.00440325055804"
        ],
        [
         "17",
         "300017",
         "82.46044812883649"
        ],
        [
         "18",
         "300018",
         "83.18532344273159"
        ],
        [
         "19",
         "300019",
         "77.71712820870536"
        ],
        [
         "20",
         "300020",
         "82.86251286097935"
        ],
        [
         "21",
         "300021",
         "68.21156420026507"
        ],
        [
         "22",
         "300022",
         "83.59626770019531"
        ],
        [
         "23",
         "300023",
         "81.53378186907086"
        ],
        [
         "24",
         "300024",
         "83.38943045479911"
        ],
        [
         "25",
         "300025",
         "92.68773542131696"
        ],
        [
         "26",
         "300026",
         "82.82888793945312"
        ],
        [
         "27",
         "300027",
         "81.63006264822823"
        ],
        [
         "28",
         "300028",
         "81.62841796875"
        ],
        [
         "29",
         "300029",
         "88.5713631766183"
        ],
        [
         "30",
         "300030",
         "82.61730848039899"
        ],
        [
         "31",
         "300031",
         "80.7669176374163"
        ],
        [
         "32",
         "300032",
         "85.6407492501395"
        ],
        [
         "33",
         "300033",
         "77.14100319998605"
        ],
        [
         "34",
         "300034",
         "78.72824423653739"
        ],
        [
         "35",
         "300035",
         "80.16949462890625"
        ],
        [
         "36",
         "300036",
         "82.19214630126953"
        ],
        [
         "37",
         "300037",
         "80.94391087123326"
        ],
        [
         "38",
         "300038",
         "78.84672328404018"
        ],
        [
         "39",
         "300039",
         "78.92323303222656"
        ],
        [
         "40",
         "300040",
         "80.67180524553571"
        ],
        [
         "41",
         "300041",
         "81.68013109479632"
        ],
        [
         "42",
         "300042",
         "82.829099382673"
        ],
        [
         "43",
         "300043",
         "80.58871132986886"
        ],
        [
         "44",
         "300044",
         "82.83802468436105"
        ],
        [
         "45",
         "300045",
         "86.92673819405692"
        ],
        [
         "46",
         "300046",
         "82.36749158586774"
        ],
        [
         "47",
         "300047",
         "82.81223515101841"
        ],
        [
         "48",
         "300048",
         "82.29374585832868"
        ],
        [
         "49",
         "300049",
         "76.18458557128906"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 200000
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300000</td>\n",
       "      <td>79.989791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>300001</td>\n",
       "      <td>83.249299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300002</td>\n",
       "      <td>86.406607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>300003</td>\n",
       "      <td>76.559465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300004</td>\n",
       "      <td>79.384238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>499995</td>\n",
       "      <td>81.018658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>499996</td>\n",
       "      <td>80.295455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>499997</td>\n",
       "      <td>82.905794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>499998</td>\n",
       "      <td>82.028964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>499999</td>\n",
       "      <td>82.748705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id      Price\n",
       "0       300000  79.989791\n",
       "1       300001  83.249299\n",
       "2       300002  86.406607\n",
       "3       300003  76.559465\n",
       "4       300004  79.384238\n",
       "...        ...        ...\n",
       "199995  499995  81.018658\n",
       "199996  499996  80.295455\n",
       "199997  499997  82.905794\n",
       "199998  499998  82.028964\n",
       "199999  499999  82.748705\n",
       "\n",
       "[200000 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_state_dict = torch.load('models/best_nn_emb.pth', weights_only=True)\n",
    "nn_model_best = NeuralNetwEmbedding(embedding_sizes=embedding_sizes, num_numerical=49, hidden_units=64,output_dim= 1)\n",
    "nn_model_best = nn_model_best.to(device)\n",
    "nn_model_best.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "preds =  make_predictions(model_w_emb, X_test) \n",
    "xgb = pd.read_csv('submission_v1.csv',index_col=None)\n",
    "xgb_preds = xgb.Price\n",
    "new_preds = (preds + xgb_preds) / 2\n",
    "\n",
    "\n",
    "sub = pd.read_csv(\"data/sample_submission.csv\")\n",
    "sub.Price = new_preds\n",
    "sub.to_csv(f\"results_ensembled.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
